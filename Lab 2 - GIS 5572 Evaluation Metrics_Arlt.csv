Evaluation Approach / Metric,Appropriate Data Types,Mathematic Definition (if applicable),ArcPy function (if applicable),How to do in python,What metrics is this approach similar / different to?,Sources
Confusion Matrix,Categorical (classification),"A table showing TP, FP, FN, TN",arcpy.sa.TabulateArea() or arcpy.sa.ZonalStatisticsAsTable(),from sklearn.metrics import confusion_matrix,"Related to accuracy, precision, recall","Scikit-learn documentation, Fawcett (2006)"
Accuracy,Categorical (classification),(TP+TN​) / (TP+TN+FP+FN),,"accuracy_score(y_true, y_pred) in sklearn","Related to precision, recall, F1-score","Sokolova & Lapalme (2009), Scikit-learn docs"
Precision,Categorical (classification),TP​ / (TP+FP),,"precision_score(y_true, y_pred) in sklearn",Related to recall and F1-score,"Powers (2011), Scikit-learn docs"
Recall,Categorical (classification),TP​ / (TP+FN),,"recall_score(y_true, y_pred) in sklearn",Related to precision and F1-score,"Sokolova & Lapalme (2009), Scikit-learn docs"
True Positives,Categorical (classification),Count of correctly predicted positive cases,,"Extract from confusion_matrix(y_true, y_pred)",Component of confusion matrix,Scikit-learn documentation
False Positives,Categorical (classification),Count of incorrectly predicted positive cases,,"Extract from confusion_matrix(y_true, y_pred)",Component of confusion matrix,Scikit-learn documentation
Receiver Operator Characteristic (ROC) Curve and Area Under the Curve (AUC-ROC),Categorical (classification),"Plot of TPR vs. FPR, AUC = integral under curve",,"roc_curve(y_true, y_scores) and roc_auc_score(y_true, y_scores) from sklearn",Related to precision-recall curve,"Fawcett (2006), Scikit-learn docs"
R-squared (R2),Continuous (regression),1 − ( ∑(yi​−yiv​)^2​ / ∑(yi​−yˉ​)^2),arcpy.stats.OrdinaryLeastSquares(),"r2_score(y_true, y_pred) from sklearn","Similar to adjusted R2, RMSE","Wooldridge (2016), Scikit-learn docs"
Adjusted R-Squared,Continuous (regression),1 − (1−R2) (n−1 / n−k−1​),,Adjust using r2_score and formula manually,Adjusts R2 for number of predictors,"Wooldridge (2016), Statsmodels docs"
Root Mean Square Error (RMSE),Continuous (regression),(1/n ∑(yi​−y^​i​)^2) ^ 1/2​,arcpy.RasterToNumPyArray(),"mean_squared_error(y_true, y_pred, squared=False)","Similar to MAE, residual standard error","Willmott & Matsuura (2005), Scikit-learn docs"
Mean Absolute Error (MAE),Continuous (regression),1 / n ​∑∣yi​−y^​i​∣,,"from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(y_true, y_pred)",,"mean_absolute_error(y_true, y_pred)"
Residual Standard Error (RSE),Continuous (regression),n−k−1∑(yi​−y^​i​)2​​,,Compute using RMSE formula with degrees of freedom,Related to RMSE,"Wooldridge (2016), Statsmodels docs"
Akaike’s Information Criterion (AIC),Continuous (model selection),"2k−2ln(L), where k is number of parameters",,Use statsmodels.api to get AIC from a model,"Similar to BIC, used for model comparison","Akaike (1974), Statsmodels docs"
Bayesian Information Criterion (BIC),Continuous (model selection),"kln(n)−2ln(L), where k is number of parameters",,Use statsmodels.api to get BIC from a model,Similar to AIC but penalizes complexity more,"Schwarz (1978), Statsmodels docs"